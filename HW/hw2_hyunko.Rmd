---
title: "Homework #2: Resampling" 
author: "**Your Name Here**"
date: "Due: Wed Sept 14 | 11:45am"
output: R6030::homework
---

**DS 6030 | Fall 2022 | University of Virginia**

------------------------------------------------------------------------

```{r config, echo=FALSE}
source(system.file("config/hw_config.R", package="R6030")) # knitr settings
```

# Required R packages and Directories

::: {.solution}
```{r packages, message=FALSE, warning=FALSE}
data.dir = 'https://mdporter.github.io/DS6030/data/' # data directory
library(R6030)     # functions for DS-6030
library(tidyverse) # functions for data manipulation  
```
:::

# Problem 1: Bootstrapping 

Bootstrap resampling can be used to quantify the uncertainty in a fitted curve. 

## a. Create a set of functions to generate data from the following distributions:
\begin{align*}
X &\sim \mathcal{U}(0, 2) \qquad \text{Uniform in $[0,2]$}\\
Y &= 1 + 2x + 5\sin(5x) + \epsilon \\
\epsilon &\sim \mathcal{N}(0,\, \sigma=2.5)
\end{align*}

::: {.solution}

```{r}
sim_x <- function(n) runif(n, min = 0, max = 1)   
sim_y <- function(x){               # generate Y|X from N{f(x),sd}
  n = length(x)
  f <- function(x) 1 + 2 * x + 5 * sin(5 * x) 
  f(x) + rnorm(n, mean = 0 , sd = 2.5)  # error
}
```


:::

## b. Simulate $n=100$ realizations from these distributions. Produce a scatterplot and draw the true regression line $f(x) = E[Y \mid X=x]$. Use `set.seed(211)` prior to generating the data.

::: {.solution}

```{r}
set.seed(211)

n <- 100

x <- sim_x(n)    # get x values
y <- sim_y(x)

data_train <- tibble(x, y)               # training data tibble

gg_myplot <- ggplot(data_train, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
  
gg_myplot
```


:::


## c. Fit a 5th degree polynomial. Produce a scatterplot and draw the *estimated* regression curve.

::: {.solution}

```{r}
xseq <- x
xeval <- tibble(x = xseq)

m5 <- lm(y~poly(x, degree=5), data = data_train)
yhat5 <- predict(m5, newdata =xeval)

fifth.data <- tibble(x = xseq, fifth = yhat5) %>%  # long data
  pivot_longer(-x, names_to="model", values_to="y")
  
gg_myplot + 
  geom_line(data=fifth.data, aes(color=model)) 
```


:::


## d. Make 200 bootstrap samples. For each bootstrap sample, fit a 5th degree polynomial and make predictions at `eval_pts = seq(0, 2, length=100)`
- Set the seed (use `set.seed(212)`) so your results are reproducible.
- Produce a scatterplot with the original data and add the 200 bootstrap curves

::: {.solution}

```{r}
set.seed(212)

n <- length(x) # length of observed data
M <- 200 # numbver of bootstrap samples
p <- numeric(M) # initialize vector for test statistic
data_eval<- tibble(x = seq(0,2,length=100))
YHAT <- matrix(NA, nrow(data_eval), M)

for (m in 1:M) {
  ind = sample(n, replace = TRUE)  # sample indices with replacement
  xboot = x[ind]                   # bootstrap sample
  m_boot = lm(y ~ bs(x, df = 5, Boundary.knots = kts_bdry)-1, data = data_train[ind,]) # fit bootstrap data
  # predict from bootstrap model
  YHAT[,m] = predict(m_boot, data_eval)
}

data_fit <- as_tibble(YHAT) %>%
  bind_cols(data_eval) %>%
  pivot_longer(-x, names_to = "simulation", values_to = "y") # convert to long format

ggplot(data_train, aes(x,y)) +
  geom_smooth(method = "lm", formula = as.formula('y~bs(x, df=5, deg=3, Boundary.knots = kts_bdry)-1')) +
  geom_line(data=data_fit, color="red", alpha=.1, aes(group=simulation)) +
  geom_point()
```


:::

    
## e. Calculate the pointwise 95% confidence intervals from the bootstrap samples. That is, for each $x \in {\rm eval\_pts}$, calculate the upper and lower limits such that only 5% of the curves fall outside the interval at $x$. 
- Remake the plot from part *c*, but add the upper and lower boundaries from the 95% confidence intervals. 

::: {.solution}

```{r}
quantile(p, probs = c(.025, .975)) # 95% bootstrap interval
```


:::

# Problem 2: V-Fold cross-validation with $k$ nearest neighbors

Run 10-fold cross-validation on the data generated in part 1b to select the optimal $k$ in a k-nearest neighbor (kNN) model. Then evaluate how well cross-validation performed by evaluating the performance on a large test set. The steps below will guide you.


## a. Use $10$-fold cross-validation to find the value of $k$ (i.e., neighborhood size) that provides the smallest cross-validated MSE using a kNN model. 

- Search over $k=3,4,\ldots, 40$.
- Use `set.seed(221)` prior to generating the folds to ensure the results are replicable. 
- Show the following:
    - the optimal $k$ (as determined by cross-validation)
    - the corresponding estimated MSE
    - produce a plot with $k$ on the x-axis and the estimated MSE on the y-axis (optional: add 1-standard error bars). 
- Notation: The $k$ is the tuning paramter for the kNN model. The $v=10$ is the number of folds in V-fold cross-validation. Don't get yourself confused.


::: {.solution}

Add solution here

:::


## b. The $k$ (number of neighbors) in a kNN model determines the effective degrees of freedom *edf*. What is the optimal *edf*? Be sure to use the correct sample size when making this calculation. Produce a plot similar to that from part *a*, but use *edf* (effective degrees of freedom) on the x-axis. 


::: {.solution}

Add solution here

:::


## c. After running cross-validation, a final model fit from *all* of the training data needs to be produced to make predictions. What value of $k$ would you choose? Why? 


::: {.solution}

Add solution here

:::

## d. Now we will see how well cross-validation performed. Simulate a test data set of $50000$ observations from the same distributions. Use `set.seed(223)` prior to generating the test data. 
- Fit a set of kNN models, using the full training data, and calculate the mean squared error (MSE) on the test data for each model. Use the same $k$ values in *a*. 
- Report the optimal $k$, the corresponding *edf*, and MSE based on the test set.

::: {.solution}

Add solution here

:::

## e. Plot both the cross-validation estimated and (true) error calculated from the test data on the same plot. See Figure 5.6 in ISL (pg 182) as a guide. 
- Produce two plots: one with $k$ on the x-axis and one with *edf* on the x-axis.
- Each plot should have two lines: one from part *a* and one from part *d* 
    
::: {.solution}

Add solution here

:::
    
## f. Based on the plots from *e*, does it appear that cross-validation worked as intended? How sensitive is the choice of $k$ on the resulting test MSE?      

::: {.solution}

Add solution here

:::







