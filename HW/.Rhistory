nrow(X.train)
length(Y.train)
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
X.train <- as.matrix(train %>% dplyr::select(-price))
#X.train
Y.train <- train %>% pull(price)
Y.train
X.test <- as.matrix(test)
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
X.train <- as.matrix(train %>% dplyr::select(-price))
#X.train
Y.train <- train %>% pull(price)
X.test <- as.matrix(test)
#--ElasticNet
a = 0.8
#set alpha for elastic net
fit.enet = cv.glmnet(X.train,Y.train, alpha=a, foldid= 10, labels = "Response")
View(X.train)
View(X.test)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = read.csv('realestate-train.csv'),
test = read.csv('realestate-test.csv')
)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train,
test = test
)
View(train)
View(test)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X.train = X$x
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
#X.train = X$x
#X.train
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
Y.train = X$price
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
X[1:length(X), price]
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
X[1:length(X), 1]
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
#X
X[, 1]
$Y.train = X$price
View(train)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
X.train = X[,2:13]
Y.train = X[, 1]
Y.train
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
#train <- read.csv('realestate-train.csv')
#test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
X.train = X[,2:13]
X.train
Y.train = X[, 1]
#Y.train
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
X = glmnet::makeX(
train = train
)
X
X.train = X[,2:13]
X.train
Y.train = X[, 1]
#Y.train
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
#--ElasticNet
a = 0.8
#set alpha for elastic net
fit.enet = cv.glmnet(X.train,Y.train, alpha=a, foldid= 10, labels = "Response")
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
unique(train$BldgType)
unique(train$HouseStyle)
train <- train %>% mutate(PoolArea = ifelse(PoolArea != 0, 1, 0),
CentralAir = ifelse(CentralAir == "Y", 1, 0),
BldgType = case_when(
train$BldgType == "1Fam" ~ 0,
train$BldgType == "2fmCon" ~ 1,
train$BldgType == "Duplex" ~ 2,
train$BldgType == "TwnhsE" ~ 3,
train$BldgType == "Twnhs" ~ 4),
HouseStyle = case_when(
train$HouseStyle == "2Story" ~ 0,
train$HouseStyle == "1.5Fin"  ~ 1,
train$HouseStyle == "1Story" ~ 2,
train$HouseStyle == "1.5Unf" ~ 3,
train$HouseStyle == "SLvl"  ~ 4,
train$HouseStyle == "2.5Unf" ~ 5,
train$HouseStyle == "2.5Fin" ~ 6,
train$HouseStyle == "SFoyer" ~ 7,
))
test <- test %>% mutate(PoolArea = ifelse(PoolArea != 0, 1, 0),
CentralAir = ifelse(CentralAir == "Y", 1, 0),
BldgType = case_when(
test$BldgType == "1Fam" ~ 0,
test$BldgType == "2fmCon" ~ 1,
test$BldgType == "Duplex" ~ 2,
test$BldgType == "TwnhsE" ~ 3,
test$BldgType == "Twnhs" ~ 4),
HouseStyle = case_when(
test$HouseStyle == "2Story" ~ 0,
test$HouseStyle == "1.5Fin"  ~ 1,
test$HouseStyle == "1Story" ~ 2,
test$HouseStyle == "1.5Unf" ~ 3,
test$HouseStyle == "SLvl"  ~ 4,
test$HouseStyle == "2.5Unf" ~ 5,
test$HouseStyle == "2.5Fin" ~ 6,
test$HouseStyle == "SFoyer" ~ 7,
))
regnull <- lm(price ~ 1, data = train)
regfull <- lm(price ~ ., data = train)
step(regnull, scope = list(lower = regnull, upper = regfull), direction = "both")
X = glmnet::makeX(
train = train,
test = test
)
X = glmnet::makeX(
train = train
)
X
X.train = X[,2:13]
X.train
Y.train = X[, 1]
#Y.train
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
X = glmnet::makeX(
train = train
)
#X
X.train = X[,2:13]
#X.train
Y.train = X[, 1]
Y.train
#X.train <- as.matrix(train %>% dplyr::select(-price))
#Y.train <- train %>% pull(price)
#X.test <- as.matrix(test)
X = glmnet::makeX(
train = train
)
#X
X.train = X[,2:13]
#X.train
Y.train = X[, 1]
#Y.train
X.test <- as.matrix(test)
#--ElasticNet
a = 0.8
#set alpha for elastic net
fit.enet = cv.glmnet(X.train,Y.train, alpha=a, foldid= 10, labels = "Response")
View(X.train)
X = glmnet::makeX(
train = train
)
#X
X.train = X[,2:13]
#X.train
Y.train = X[, 1]
Y.train[1:5]
X.test <- as.matrix(test)
X[,2:13]
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
#-- Load raw data
data.url = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'
prostate = readr::read_tsv(data.url, col_select=-1) # remove row numbers Then get the model matrices using glmnet::makeX()
#-- Get model matrices (returns a list of ` x` and ` xtest` )
X = glmnet::makeX( train = prostate %>% filter(train) %>% select(-lpsa,-train), test = prostate %>% filter(!train) %>% select(-lpsa,-train) ) X.train = X$x
#-- Load raw data
data.url = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'
prostate = readr::read_tsv(data.url, col_select=-1) # remove row numbers Then get the model matrices using glmnet::makeX()
#-- Get model matrices (returns a list of ` x` and ` xtest` )
X = glmnet::makeX(train = prostate %>% filter(train) %>% select(-lpsa,-train),
test = prostate %>% filter(!train) %>% select(-lpsa,-train) )
X.train = X$x
Y.train = prostate %>% filter(train) %>% pull(lpsa)
X.test = X$xtest
Y.test = prostate %>% filter(!train) %>% pull(lpsa)
X.train
Y.train
X.train
source(system.file("config/hw_config.R", package="R6030")) # knitr settings
# options(dplyr.summarise.inform = FALSE)  # ignore dplyr message about grouping
data.dir = 'https://mdporter.github.io/DS6030/data/' # data directory
library(mlbench)
library(glmnet)
library(R6030)     # functions for DS-6030
library(tidyverse) # functions for data manipulation
library(ggpubr)
library(dplyr)
library(GGally)
library(mlbench)
library(glmnet)
#-- Data Generating Function
getData <- function(n) mlbench.friedman1(n, sd=2) # data generating function
#-- Settings
n.train = 8000      # number of training obs
n.test = 2000       # number of test obs
K = 10             # number of CV folds
alpha = 0        # glmnet tuning alpha (1 = lasso, 0 = ridge)
M = 100              # number of simulations
lambda_min <- c()
lambda_1se <- c()
mse_min <- c()
mse_1se <- c()
for(m in 1:M) {
# 1. Generate Training Data
train <- getData(n.train)
# 2. Build Training Models using cross-validation, e.g., cv.glmnet()
X.train <- train$x
Y.train <- train$y
ridge_cv <- cv.glmnet(X.train, Y.train, alpha = alpha, nfolds = K)
# 3. get lambda that minimizes cv error and 1 SE rule
lambda.min <- ridge_cv$lambda.min
lambda.1se <- ridge_cv$lambda.1se
lambda_min <- append(lambda_min, lambda.min)
lambda_1se <- append(lambda_1se, lambda.1se)
# 4. Generate Test Data
#set.seed(2022)
test <- getData(n.test)
X.test <- test$x
Y.test <- test$y
# 5. Predict y values for test data (for each model: min, 1SE)
yhat_min <- predict(ridge_cv, X.test, s = "lambda.min")
yhat_1se <- predict(ridge_cv, X.test, s = "lambda.1se")
# 6. Evaluate predictions
mse_min <- append(mse_min, mean((Y.test - yhat_min) ^ 2) )
mse_1se <- append(mse_1se, mean((Y.test - yhat_1se) ^ 2) )
}
a <- data.frame(lambda_min = lambda_min, mse_min= mse_min, lambda_1se = lambda_1se ,mse_1se = mse_1se)
a
mean(a$mse_min)
mean(a$mse_1se)
t.test(a$mse_min, a$mse_1se, paired = TRUE)
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
unique(train$HouseStyle)
train <- train %>% mutate(PoolArea = ifelse(PoolArea != 0, 1, 0),
CentralAir = ifelse(CentralAir == "Y", 1, 0),
BldgType = case_when(
train$BldgType == "1Fam" ~ 0,
train$BldgType == "2fmCon" ~ 1,
train$BldgType == "Duplex" ~ 2,
train$BldgType == "TwnhsE" ~ 3,
train$BldgType == "Twnhs" ~ 4),
HouseStyle = case_when(
train$HouseStyle == "2Story" ~ 0,
train$HouseStyle == "1.5Fin"  ~ 1,
train$HouseStyle == "1Story" ~ 2,
train$HouseStyle == "1.5Unf" ~ 3,
train$HouseStyle == "SLvl"  ~ 4,
train$HouseStyle == "2.5Unf" ~ 5,
train$HouseStyle == "2.5Fin" ~ 6,
train$HouseStyle == "SFoyer" ~ 7,
))
test <- test %>% mutate(PoolArea = ifelse(PoolArea != 0, 1, 0),
CentralAir = ifelse(CentralAir == "Y", 1, 0),
BldgType = case_when(
test$BldgType == "1Fam" ~ 0,
test$BldgType == "2fmCon" ~ 1,
test$BldgType == "Duplex" ~ 2,
test$BldgType == "TwnhsE" ~ 3,
test$BldgType == "Twnhs" ~ 4),
HouseStyle = case_when(
test$HouseStyle == "2Story" ~ 0,
test$HouseStyle == "1.5Fin"  ~ 1,
test$HouseStyle == "1Story" ~ 2,
test$HouseStyle == "1.5Unf" ~ 3,
test$HouseStyle == "SLvl"  ~ 4,
test$HouseStyle == "2.5Unf" ~ 5,
test$HouseStyle == "2.5Fin" ~ 6,
test$HouseStyle == "SFoyer" ~ 7,
))
regnull <- lm(price ~ 1, data = train)
regfull <- lm(price ~ ., data = train)
step(regnull, scope = list(lower = regnull, upper = regfull), direction = "both")
X = glmnet::makeX(
train = train
)
#X
X.train = X[,2:13]
#X.train
Y.train = X[, 1]
Y.train[1:5]
X.test <- as.matrix(test)
X = glmnet::makeX(
train = train %>% dplyr::select(-price),
test = test %>% dplyr::select(-price)
)
View(train)
train %>% dplyr::select(-price),
train
train %>% select(-price)
X = glmnet::makeX(
train = train %>% select(-price),
test = test %>% select(-price)
)
test
X = glmnet::makeX(
train = train %>% select(-price),
test = test
)
#X
X.train = X$x
Y.train = train$price
X.test = X$xtest
X.train
Y.train
X.test
#--ElasticNet
a = 0.8
#set alpha for elastic net
fit.enet = cv.glmnet(X.train,Y.train, alpha=a, foldid= 10, labels = "Response")
#--ElasticNet
a = 0.8
#set alpha for elastic net
fit.enet = cv.glmnet(X.train,Y.train, alpha=a, nfolds= 10)
beta.enet = coef(fit.enet, s="lambda.min")
yhat.enet = predict(fit.enet, newx = X.test, s = "lambda.min")
yhat.enet
beta.enet
test
test <- test$mutate(yhat = yhat.enet)
test <- test %>% mutate(yhat = yhat.enet)
test
test
View(test)
yhat.enet
test <- test %>% mutate(yhat = yhat.enet[,1])
test
source(system.file("config/hw_config.R", package="R6030")) # knitr settings
# options(dplyr.summarise.inform = FALSE)  # ignore dplyr message about grouping
data.dir = 'https://mdporter.github.io/DS6030/data/' # data directory
library(mlbench)
library(glmnet)
library(R6030)     # functions for DS-6030
library(tidyverse) # functions for data manipulation
library(ggpubr)
library(dplyr)
library(GGally)
library(mlbench)
library(glmnet)
#-- Data Generating Function
getData <- function(n) mlbench.friedman1(n, sd=2) # data generating function
#-- Settings
n.train = 8000      # number of training obs
n.test = 2000       # number of test obs
K = 10             # number of CV folds
alpha = 0        # glmnet tuning alpha (1 = lasso, 0 = ridge)
M = 100              # number of simulations
lambda_min <- c()
lambda_1se <- c()
mse_min <- c()
mse_1se <- c()
for(m in 1:M) {
# 1. Generate Training Data
train <- getData(n.train)
# 2. Build Training Models using cross-validation, e.g., cv.glmnet()
X.train <- train$x
Y.train <- train$y
ridge_cv <- cv.glmnet(X.train, Y.train, alpha = alpha, nfolds = K)
# 3. get lambda that minimizes cv error and 1 SE rule
lambda.min <- ridge_cv$lambda.min
lambda.1se <- ridge_cv$lambda.1se
lambda_min <- append(lambda_min, lambda.min)
lambda_1se <- append(lambda_1se, lambda.1se)
# 4. Generate Test Data
#set.seed(2022)
test <- getData(n.test)
X.test <- test$x
Y.test <- test$y
# 5. Predict y values for test data (for each model: min, 1SE)
yhat_min <- predict(ridge_cv, X.test, s = "lambda.min")
yhat_1se <- predict(ridge_cv, X.test, s = "lambda.1se")
# 6. Evaluate predictions
mse_min <- append(mse_min, mean((Y.test - yhat_min) ^ 2) )
mse_1se <- append(mse_1se, mean((Y.test - yhat_1se) ^ 2) )
}
a <- data.frame(lambda_min = lambda_min, mse_min= mse_min, lambda_1se = lambda_1se ,mse_1se = mse_1se)
a
mean(a$mse_min)
mean(a$mse_1se)
t.test(a$mse_min, a$mse_1se, paired = TRUE)
train <- read.csv('realestate-train.csv')
test <- read.csv('realestate-test.csv')
unique(train$HouseStyle)
train <- train %>% mutate(PoolArea = ifelse(PoolArea != 0, 1, 0),
CentralAir = ifelse(CentralAir == "Y", 1, 0),
BldgType = case_when(
train$BldgType == "1Fam" ~ 0,
train$BldgType == "2fmCon" ~ 1,
train$BldgType == "Duplex" ~ 2,
train$BldgType == "TwnhsE" ~ 3,
train$BldgType == "Twnhs" ~ 4),
HouseStyle = case_when(
train$HouseStyle == "2Story" ~ 0,
train$HouseStyle == "1.5Fin"  ~ 1,
train$HouseStyle == "1Story" ~ 2,
train$HouseStyle == "1.5Unf" ~ 3,
train$HouseStyle == "SLvl"  ~ 4,
train$HouseStyle == "2.5Unf" ~ 5,
train$HouseStyle == "2.5Fin" ~ 6,
train$HouseStyle == "SFoyer" ~ 7,
))
test <- test %>% mutate(PoolArea = ifelse(PoolArea != 0, 1, 0),
CentralAir = ifelse(CentralAir == "Y", 1, 0),
BldgType = case_when(
test$BldgType == "1Fam" ~ 0,
test$BldgType == "2fmCon" ~ 1,
test$BldgType == "Duplex" ~ 2,
test$BldgType == "TwnhsE" ~ 3,
test$BldgType == "Twnhs" ~ 4),
HouseStyle = case_when(
test$HouseStyle == "2Story" ~ 0,
test$HouseStyle == "1.5Fin"  ~ 1,
test$HouseStyle == "1Story" ~ 2,
test$HouseStyle == "1.5Unf" ~ 3,
test$HouseStyle == "SLvl"  ~ 4,
test$HouseStyle == "2.5Unf" ~ 5,
test$HouseStyle == "2.5Fin" ~ 6,
test$HouseStyle == "SFoyer" ~ 7,
))
regnull <- lm(price ~ 1, data = train)
regfull <- lm(price ~ ., data = train)
step(regnull, scope = list(lower = regnull, upper = regfull), direction = "both")
X = glmnet::makeX(
train = train %>% select(-price),
test = test
)
#X
X.train = X$x
Y.train = train$price
X.test = X$xtest
#--ElasticNet
a = 0.8
#set alpha for elastic net
fit.enet = cv.glmnet(X.train,Y.train, alpha=a, nfolds= 10)
beta.enet = coef(fit.enet, s="lambda.min")
yhat.enet = predict(fit.enet, newx = X.test, s = "lambda.min")
test <- test %>% mutate(yhat = yhat.enet[,1])
test
test <- test %>% mutate(yhat = yhat.enet[,1])
test
write_csv(test, 'ko_hyunsuk.csv')
fit.enet
